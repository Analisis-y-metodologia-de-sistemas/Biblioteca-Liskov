#!/usr/bin/env python3
"""
Runner principal para ejecutar todos los tests del sistema
"""

import sys
import os
import unittest
import time
from datetime import datetime

# Agregar el path del proyecto
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))


def run_tests():
    """Ejecuta todos los tests del sistema"""
    
    print("ðŸ§ª EJECUTANDO TESTS DEL SISTEMA BIBLIOTECA LISKOV")
    print("=" * 60)
    print(f"ðŸ“… Fecha: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print()
    
    # Configurar el loader y suite
    loader = unittest.TestLoader()
    start_dir = os.path.dirname(__file__)
    
    # Descubrir todos los tests
    suite = loader.discover(start_dir, pattern='test_*.py')
    
    # Configurar el runner con verbosidad
    runner = unittest.TextTestRunner(
        verbosity=2,
        stream=sys.stdout,
        descriptions=True,
        failfast=False
    )
    
    # Ejecutar tests
    start_time = time.time()
    result = runner.run(suite)
    end_time = time.time()
    
    # Mostrar resumen
    print()
    print("ðŸ“Š RESUMEN DE EJECUCIÃ“N")
    print("=" * 40)
    print(f"â±ï¸  Tiempo total: {end_time - start_time:.2f} segundos")
    print(f"âœ… Tests ejecutados: {result.testsRun}")
    print(f"âŒ Fallos: {len(result.failures)}")
    print(f"ðŸ’¥ Errores: {len(result.errors)}")
    print(f"â© Omitidos: {len(result.skipped)}")
    
    # Mostrar detalles de fallos si los hay
    if result.failures:
        print()
        print("âŒ FALLOS DETECTADOS:")
        print("-" * 30)
        for test, traceback in result.failures:
            print(f"ðŸ”´ {test}: {traceback}")
    
    # Mostrar detalles de errores si los hay
    if result.errors:
        print()
        print("ðŸ’¥ ERRORES DETECTADOS:")
        print("-" * 30)
        for test, traceback in result.errors:
            print(f"ðŸ”´ {test}: {traceback}")
    
    # Resultado final
    if result.wasSuccessful():
        print()
        print("ðŸŽ‰ Â¡TODOS LOS TESTS PASARON EXITOSAMENTE!")
        return 0
    else:
        print()
        print("âš ï¸  ALGUNOS TESTS FALLARON - REVISAR ARRIBA")
        return 1


def run_unit_tests_only():
    """Ejecuta solo los tests unitarios"""
    print("ðŸ§ª EJECUTANDO SOLO TESTS UNITARIOS")
    print("=" * 40)
    
    loader = unittest.TestLoader()
    unit_dir = os.path.join(os.path.dirname(__file__), 'unit')
    
    suite = loader.discover(unit_dir, pattern='test_*.py')
    runner = unittest.TextTestRunner(verbosity=2)
    
    result = runner.run(suite)
    return 0 if result.wasSuccessful() else 1


def run_integration_tests_only():
    """Ejecuta solo los tests de integraciÃ³n"""
    print("ðŸ§ª EJECUTANDO SOLO TESTS DE INTEGRACIÃ“N")
    print("=" * 40)
    
    loader = unittest.TestLoader()
    integration_dir = os.path.join(os.path.dirname(__file__), 'integration')
    
    suite = loader.discover(integration_dir, pattern='test_*.py')
    runner = unittest.TextTestRunner(verbosity=2)
    
    result = runner.run(suite)
    return 0 if result.wasSuccessful() else 1


def show_test_coverage():
    """Muestra informaciÃ³n sobre la cobertura de tests"""
    print("ðŸ“‹ COBERTURA DE TESTS")
    print("=" * 30)
    
    unit_tests = [
        "âœ… UsuarioService - Registro, bÃºsqueda, validaciones",
        "âœ… ItemBibliotecaService - CRUD, bÃºsquedas, categorÃ­as", 
        "âœ… PrestamoService - PrÃ©stamos, devoluciones, multas",
        "âœ… ReservaService - Reservas, cancelaciones",
        "âœ… MultaService - Pagos, listados",
        "âœ… AuthService - AutenticaciÃ³n, sesiones, passwords"
    ]
    
    integration_tests = [
        "âœ… Flujo completo prÃ©stamo con multa",
        "âœ… Sistema de reservas end-to-end",
        "âœ… BÃºsquedas y filtros integrados",
        "âœ… AutenticaciÃ³n completa",
        "âœ… Validaciones y restricciones"
    ]
    
    print("ðŸ”§ TESTS UNITARIOS:")
    for test in unit_tests:
        print(f"  {test}")
    
    print()
    print("ðŸ”„ TESTS DE INTEGRACIÃ“N:")
    for test in integration_tests:
        print(f"  {test}")
    
    print()
    print("ðŸ“Š ESTADÃSTICAS:")
    print(f"  â€¢ {len(unit_tests)} suites de tests unitarios")
    print(f"  â€¢ {len(integration_tests)} suites de tests de integraciÃ³n") 
    print(f"  â€¢ ~50+ casos de prueba individuales")
    print(f"  â€¢ Cobertura: Servicios, repositorios, casos de uso")


if __name__ == '__main__':
    if len(sys.argv) > 1:
        if sys.argv[1] == '--unit':
            sys.exit(run_unit_tests_only())
        elif sys.argv[1] == '--integration':
            sys.exit(run_integration_tests_only())
        elif sys.argv[1] == '--coverage':
            show_test_coverage()
            sys.exit(0)
        elif sys.argv[1] == '--help':
            print("ðŸ§ª RUNNER DE TESTS - Sistema Biblioteca Liskov")
            print()
            print("Uso:")
            print("  python test_runner.py           # Ejecutar todos los tests")
            print("  python test_runner.py --unit    # Solo tests unitarios")
            print("  python test_runner.py --integration  # Solo tests de integraciÃ³n")
            print("  python test_runner.py --coverage     # Mostrar cobertura")
            print("  python test_runner.py --help         # Esta ayuda")
            sys.exit(0)
    
    # Ejecutar todos los tests por defecto
    sys.exit(run_tests())